# Methodology Adherence Checklist - Phase 0

**Purpose**: Track and score how well Phase 0 discovery follows the designed methodology.

**Version**: 1.0  
**Last Updated**: 2025-11-07  
**Location**: `test/.sdlc/primitives/checklists/methodology-adherence_checklist.md`

---

## Overview

This checklist measures whether Phase 0 discovery is being conducted according to the agentic SDLC framework design. It's not about artifact quality (that's the completion checklist) - it's about process adherence.

**Why This Matters**:
- Ensures consistency across projects
- Validates the methodology through testing
- Identifies gaps in instructions/workflows
- Provides data for framework improvements

---

## Scoring System

**Total Possible Score**: 12 points  
**Passing Score**: 10+ points (83%)

**Grade Scale**:
- **A (11-12 pts)**: Excellent adherence - methodology followed rigorously
- **B (9-10 pts)**: Good adherence - minor deviations but spirit followed
- **C (7-8 pts)**: Moderate adherence - some methodology components skipped
- **D (5-6 pts)**: Poor adherence - methodology partially followed
- **F (0-4 pts)**: Failed adherence - methodology not followed

---

## Category 1: Agent Instructions (0-3 points)

### 1.1 Discovery Facilitator Instructions Loaded (0-1 point)

**Criteria**:
- [ ] 1.0 pt - Instructions explicitly loaded at session start
- [ ] 0.5 pt - Instructions referenced but not formally loaded
- [ ] 0.0 pt - Instructions not used

**Evidence Required**:
- Session transcript showing instructions were pasted/loaded
- OR reference to instructions file in session notes
- OR clear use of methodology frameworks (Five Whys, Jobs-to-be-Done)

**Score**: [ ] / 1.0

**Notes**: _[How were instructions used or why weren't they?]_

---

### 1.2 Feasibility Analyzer Instructions Loaded (0-1 point)

**Criteria**:
- [ ] 1.0 pt - Instructions explicitly loaded when conducting feasibility analysis
- [ ] 0.5 pt - Feasibility analysis done but instructions not formally loaded
- [ ] 0.0 pt - Feasibility analysis skipped or done without methodology

**Evidence Required**:
- Session transcript showing instructions loaded before feasibility analysis
- OR feasibility report clearly follows four-dimension framework from instructions

**Score**: [ ] / 1.0

**Notes**: _[How were instructions used or why weren't they?]_

---

### 1.3 Synthesis Agent Guidance Followed (0-1 point)

**Criteria**:
- [ ] 1.0 pt - Explicit synthesis step conducted using synthesis guidance
- [ ] 0.5 pt - Problem statement created but without formal synthesis step
- [ ] 0.0 pt - No problem statement synthesized from interviews

**Evidence Required**:
- Session notes showing "Step 3: Problem Synthesis" conducted
- OR problem statement that clearly integrates all interview findings

**Score**: [ ] / 1.0

**Notes**: _[How was synthesis conducted or why wasn't it?]_

---

**Category 1 Subtotal**: [ ] / 3.0

---

## Category 2: Workflows (0-3 points)

### 2.1 Discovery Workflow Steps Followed (0-1.5 points)

**Criteria**:
- [ ] 1.5 pt - All 7 steps explicitly followed in order
- [ ] 1.0 pt - 5-6 steps followed (minor skips/reordering)
- [ ] 0.5 pt - 3-4 steps followed (major gaps)
- [ ] 0.0 pt - Workflow not followed (ad-hoc process)

**Seven Workflow Steps**:
1. [ ] Step 1: Initiate Discovery
2. [ ] Step 2: Problem Exploration (Interviews)
3. [ ] Step 3: Problem Synthesis
4. [ ] Step 4: Feasibility Analysis
5. [ ] Step 5: Risk Assessment
6. [ ] Step 6: Success Criteria Definition
7. [ ] Step 7: Validation

**Evidence Required**:
- Session notes or phase0-context.md showing step progression
- Artifacts created at each step

**Score**: [ ] / 1.5

**Notes**: _[Which steps were skipped and why?]_

---

### 2.2 Interview Workflow Used for Interviews (0-1.5 points)

**Criteria**:
- [ ] 1.5 pt - Interview workflow explicitly followed for all interviews
- [ ] 1.0 pt - Interview workflow followed for most interviews
- [ ] 0.5 pt - Interview workflow referenced but not strictly followed
- [ ] 0.0 pt - Interviews conducted without workflow guidance

**Interview Workflow Steps**:
1. [ ] Pre-interview preparation (research stakeholder, prepare questions)
2. [ ] Opening (set context, establish rapport)
3. [ ] Problem exploration (open-ended questions)
4. [ ] Root cause analysis (Five Whys)
5. [ ] Impact & context (quantify, identify constraints)
6. [ ] Closing (summarize, clarify, next steps)
7. [ ] Documentation (create transcript using template)

**Evidence Required**:
- Interview transcripts showing structured approach
- Five Whys analysis documented in interviews
- Jobs-to-be-Done insights captured

**Score**: [ ] / 1.5

**Notes**: _[How closely was interview workflow followed?]_

---

**Category 2 Subtotal**: [ ] / 3.0

---

## Category 3: Templates (0-3 points)

### 3.1 Interview Transcript Template Used (0-1 point)

**Criteria**:
- [ ] 1.0 pt - All interview transcripts follow template structure exactly
- [ ] 0.5 pt - Interview transcripts partially follow template (some sections)
- [ ] 0.0 pt - Interview transcripts don't use template

**Template Required Sections**:
- [ ] Metadata (date, stakeholder, duration, session number)
- [ ] Context
- [ ] Key questions & responses
- [ ] Implicit requirements identified
- [ ] Contradictions flagged
- [ ] Open questions
- [ ] Next steps

**Evidence Required**:
- Review 3 interview transcripts and verify template compliance

**Score**: [ ] / 1.0

**Notes**: _[Template compliance level and any deviations]_

---

### 3.2 Problem Statement Template Used (0-1 point)

**Criteria**:
- [ ] 1.0 pt - Problem statement follows template structure exactly
- [ ] 0.5 pt - Problem statement partially follows template
- [ ] 0.0 pt - Problem statement doesn't use template OR no problem statement created

**Template Required Sections**:
- [ ] Problem Definition
- [ ] Impact (quantified)
- [ ] Root Cause Analysis (Five Whys)
- [ ] Constraints
- [ ] Success Criteria
- [ ] Stakeholder Perspectives

**Evidence Required**:
- Review problem statement artifact and compare to template

**Score**: [ ] / 1.0

**Notes**: _[Template compliance level and any deviations]_

---

### 3.3 Feasibility & Risk Templates Used (0-1 point)

**Criteria**:
- [ ] 1.0 pt - Both feasibility report and risk register follow templates
- [ ] 0.5 pt - One artifact follows template, other doesn't
- [ ] 0.0 pt - Neither artifact follows template OR artifacts not created

**Feasibility Template Required Sections**:
- [ ] Four-dimension assessment (Technical, Business, Resource, Timeline)
- [ ] Precedent research
- [ ] Overall score calculated
- [ ] Recommendation (GO/CONDITIONAL/NO-GO)

**Risk Template Required Sections**:
- [ ] Risk identification with categories
- [ ] Severity scoring (Likelihood × Impact)
- [ ] Mitigation strategies
- [ ] Critical risks highlighted (severity ≥20)

**Evidence Required**:
- Review both artifacts and compare to templates

**Score**: [ ] / 1.0

**Notes**: _[Template compliance level and any deviations]_

---

**Category 3 Subtotal**: [ ] / 3.0

---

## Category 4: Validation & State Tracking (0-3 points)

### 4.1 Completion Checklist Run (0-1 point)

**Criteria**:
- [ ] 1.0 pt - Phase 0 completion checklist explicitly run, results documented
- [ ] 0.5 pt - Informal validation conducted but checklist not used
- [ ] 0.0 pt - No validation conducted

**Evidence Required**:
- Validation report showing checklist results (✅/⚠️/❌ for each item)
- OR session notes showing checklist review

**Score**: [ ] / 1.0

**Notes**: _[Was checklist used? If not, why?]_

---

### 4.2 Validation Report Created (0-1 point)

**Criteria**:
- [ ] 1.0 pt - Formal validation report created in validation/ directory
- [ ] 0.5 pt - Informal validation notes but no formal report
- [ ] 0.0 pt - No validation documentation

**Required Report Contents**:
- [ ] Checklist results summary
- [ ] Pass/fail for each major deliverable
- [ ] Gaps identified
- [ ] Recommendations for improvement
- [ ] Phase 1 readiness assessment

**Evidence Required**:
- validation/phase0-completion-validation.md exists and is complete

**Score**: [ ] / 1.0

**Notes**: _[Quality and completeness of validation report]_

---

### 4.3 State Tracked in phase0-context.md (0-1 point)

**Criteria**:
- [ ] 1.0 pt - phase0-context.md maintained and updated throughout Phase 0
- [ ] 0.5 pt - phase0-context.md exists but not kept current
- [ ] 0.0 pt - No phase0-context.md file OR never updated

**Required Tracking Elements**:
- [ ] Current workflow step
- [ ] Interview progress tracker
- [ ] Artifact status tracker
- [ ] Key findings / themes
- [ ] Contradictions log
- [ ] Feasibility score (when calculated)
- [ ] Risk count (when assessed)
- [ ] Next actions

**Evidence Required**:
- phase0-context.md file exists
- File shows multiple updates (version history or date stamps)
- File accurately reflects project state

**Score**: [ ] / 1.0

**Notes**: _[How well was state tracked?]_

---

**Category 4 Subtotal**: [ ] / 3.0

---

## Overall Methodology Adherence Score

### Score Summary

| Category | Points Earned | Points Possible | Percentage |
|----------|---------------|-----------------|------------|
| 1. Agent Instructions | [ ] | 3.0 | [ ]% |
| 2. Workflows | [ ] | 3.0 | [ ]% |
| 3. Templates | [ ] | 3.0 | [ ]% |
| 4. Validation & State Tracking | [ ] | 3.0 | [ ]% |
| **TOTAL** | **[ ]** | **12.0** | **[ ]%** |

### Grade

**Letter Grade**: [ ] (A/B/C/D/F)

**Interpretation**:
- **A (11-12 pts / 92-100%)**: Exemplary adherence - methodology demonstrates high value
- **B (9-10 pts / 75-83%)**: Strong adherence - methodology mostly followed with minor gaps
- **C (7-8 pts / 58-67%)**: Adequate adherence - methodology provides guidance but not rigorously followed
- **D (5-6 pts / 42-50%)**: Weak adherence - methodology partially helpful but largely ignored
- **F (0-4 pts / 0-33%)**: Failed adherence - methodology not followed, ad-hoc process used

---

## Gap Analysis

### Gaps Identified

For each category below passing threshold, identify specific gaps:

1. **Agent Instructions Gaps** (if score < 2.5):
   - [ ] Instructions not loaded because: _[reason]_
   - [ ] Instructions loaded but not followed because: _[reason]_
   - [ ] Instructions were unclear/insufficient: _[specific issues]_

2. **Workflow Gaps** (if score < 2.5):
   - [ ] Steps skipped: _[which steps and why]_
   - [ ] Steps reordered: _[which steps and why]_
   - [ ] Workflow not followed because: _[reason]_

3. **Template Gaps** (if score < 2.5):
   - [ ] Templates not used because: _[reason]_
   - [ ] Templates were incomplete: _[what was missing]_
   - [ ] Templates were unclear: _[specific issues]_

4. **Validation/Tracking Gaps** (if score < 2.5):
   - [ ] Validation skipped because: _[reason]_
   - [ ] State tracking inconsistent because: _[reason]_
   - [ ] Validation tools insufficient: _[specific issues]_

---

## Root Cause Analysis (If Score < 10)

**If methodology adherence is below passing (10 pts)**, conduct Five Whys:

**Observable**: Methodology adherence score is [X]/12, below passing threshold

**Why #1**: Why was the methodology not followed?
- Answer: _[Root cause level 1]_

**Why #2**: Why _[answer from Why #1]_?
- Answer: _[Root cause level 2]_

**Why #3**: Why _[answer from Why #2]_?
- Answer: _[Root cause level 3]_

**Why #4**: Why _[answer from Why #3]_?
- Answer: _[Root cause level 4]_

**Why #5**: Why _[answer from Why #4]_?
- Answer: _[Root cause level 5 - actual root cause]_

**Root Cause Conclusion**:
_[Summary of fundamental reason methodology wasn't followed]_

---

## Recommendations for Framework Improvement

Based on adherence gaps, what should be improved in the methodology?

### High Priority Improvements

1. **[Component to improve]**
   - Current state: _[What exists now]_
   - Problem: _[Why it didn't work]_
   - Recommendation: _[Specific improvement]_
   - Impact: _[How this would help]_

2. **[Component to improve]**
   - Current state: _[What exists now]_
   - Problem: _[Why it didn't work]_
   - Recommendation: _[Specific improvement]_
   - Impact: _[How this would help]_

### Medium Priority Improvements

[Continue same structure]

### Low Priority Improvements

[Continue same structure]

---

## Validation

**Completed By**: _[Name/Role]_  
**Date**: _[YYYY-MM-DD]_  
**Validated By**: _[Name/Role if different]_  
**Date**: _[YYYY-MM-DD]_

**Accuracy Verification**:
- [ ] All scores are supported by evidence
- [ ] Gap analysis is objective (not subjective)
- [ ] Recommendations are specific and actionable
- [ ] Root cause analysis (if applicable) reaches fundamental issues

---

## Usage Notes

### When to Complete This Checklist

**Timing**: Complete at end of Phase 0, before declaring phase complete.

**Prerequisites**: 
- All Phase 0 artifacts created
- Completion checklist run (this measures process, not output quality)
- Session documentation available for review

### How to Score

**Objective Evidence Required**: Don't score based on memory or impressions. Review actual artifacts, session notes, and transcripts.

**Partial Credit**: Award partial credit (0.5 pts) when spirit of methodology followed even if not exact process.

**Document Rationale**: For any score < 1.0, document why in the Notes field.

### What to Do With Results

**Score ≥ 10 (Passing)**:
- Framework validation: Methodology works as designed
- Minor improvements: Address gaps identified
- Document success patterns: What worked well?

**Score < 10 (Failing)**:
- Framework issue: Methodology has usability problems
- Conduct root cause analysis: Why wasn't it followed?
- Prioritize improvements: Fix fundamental issues
- Consider re-test: After improvements, test again

---

## Example Scoring

### Example 1: Excellent Adherence (Score: 11.5/12)

**Category 1 (Agent Instructions)**: 3.0/3.0
- Discovery Facilitator instructions loaded at start: 1.0
- Feasibility Analyzer instructions loaded before analysis: 1.0
- Synthesis agent guidance followed explicitly: 1.0

**Category 2 (Workflows)**: 3.0/3.0
- All 7 discovery workflow steps followed in order: 1.5
- Interview workflow used for all 8 interviews: 1.5

**Category 3 (Templates)**: 2.5/3.0
- Interview transcripts follow template: 1.0
- Problem statement follows template: 1.0
- Feasibility report follows template; risk register partially follows: 0.5

**Category 4 (Validation & Tracking)**: 3.0/3.0
- Completion checklist run: 1.0
- Validation report created: 1.0
- phase0-context.md maintained throughout: 1.0

**Grade**: A (96%)  
**Interpretation**: Framework was followed rigorously with only minor deviation (risk register template). Demonstrates methodology is usable and valuable.

---

### Example 2: Poor Adherence (Score: 5.5/12)

**Category 1 (Agent Instructions)**: 1.5/3.0
- Discovery Facilitator instructions not loaded (interviews conducted ad-hoc): 0.0
- Feasibility Analyzer instructions not loaded (used own approach): 0.0
- Problem statement created but without formal synthesis step: 0.5

**Category 2 (Workflows)**: 1.5/3.0
- Only 4 of 7 workflow steps followed (skipped synthesis, success criteria, validation): 0.5
- Interviews had some structure but didn't follow workflow: 1.0

**Category 3 (Templates)**: 1.5/3.0
- Interview transcripts don't follow template (informal notes): 0.0
- Problem statement doesn't use template: 0.0
- Risk register created but doesn't follow template: 0.5

**Category 4 (Validation & Tracking)**: 1.0/3.0
- No completion checklist run: 0.0
- No validation report created: 0.0
- phase0-context.md existed but rarely updated: 0.5

**Grade**: D (46%)  
**Interpretation**: Methodology was largely ignored in favor of ad-hoc process. Indicates framework has usability issues OR facilitator didn't understand value. Requires root cause analysis and framework improvements.

---

**END OF METHODOLOGY ADHERENCE CHECKLIST**

This checklist ensures:
- Process consistency across projects
- Framework validation through testing
- Data-driven methodology improvements
- Gap identification for training/documentation needs

Complete this checklist for every Phase 0 test to track methodology effectiveness over time.
